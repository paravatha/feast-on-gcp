{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal Ride Hailing Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart your Kernel after installing these packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install protobuf gcsfs feast -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports and Feast Client initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-25-2021-12-53-24\n",
      "{'FEAST_CORE_URL': 'feast-release-feast-core:6565',\n",
      " 'FEAST_HISTORICAL_FEATURE_OUTPUT_LOCATION': 'file:///home/jovyan/historical_feature_output',\n",
      " 'FEAST_HISTORICAL_SERVING_URL': 'feast-release-feast-batch-serving:6566',\n",
      " 'FEAST_JUPYTER_SERVICE_PORT': 'tcp://10.79.252.133:80',\n",
      " 'FEAST_JUPYTER_SERVICE_PORT_80_TCP': 'tcp://10.79.252.133:80',\n",
      " 'FEAST_JUPYTER_SERVICE_PORT_80_TCP_ADDR': '10.79.252.133',\n",
      " 'FEAST_JUPYTER_SERVICE_PORT_80_TCP_PORT': '80',\n",
      " 'FEAST_JUPYTER_SERVICE_PORT_80_TCP_PROTO': 'tcp',\n",
      " 'FEAST_JUPYTER_SERVICE_SERVICE_HOST': '10.79.252.133',\n",
      " 'FEAST_JUPYTER_SERVICE_SERVICE_PORT': '80',\n",
      " 'FEAST_REDIS_HOST': 'feast-release-redis-master',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT': 'tcp://10.79.242.226:80',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_6565_TCP': 'tcp://10.79.242.226:6565',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_6565_TCP_ADDR': '10.79.242.226',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_6565_TCP_PORT': '6565',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_6565_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_80_TCP': 'tcp://10.79.242.226:80',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_80_TCP_ADDR': '10.79.242.226',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_80_TCP_PORT': '80',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_80_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_FEAST_CORE_SERVICE_HOST': '10.79.242.226',\n",
      " 'FEAST_RELEASE_FEAST_CORE_SERVICE_PORT': '80',\n",
      " 'FEAST_RELEASE_FEAST_CORE_SERVICE_PORT_GRPC': '6565',\n",
      " 'FEAST_RELEASE_FEAST_CORE_SERVICE_PORT_HTTP': '80',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT': 'tcp://10.79.251.72:80',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_6568_TCP': 'tcp://10.79.251.72:6568',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_6568_TCP_ADDR': '10.79.251.72',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_6568_TCP_PORT': '6568',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_6568_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_80_TCP': 'tcp://10.79.251.72:80',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_80_TCP_ADDR': '10.79.251.72',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_80_TCP_PORT': '80',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_80_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_SERVICE_HOST': '10.79.251.72',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_SERVICE_PORT': '80',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_SERVICE_PORT_GRPC': '6568',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_SERVICE_PORT_HTTP': '80',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_PORT': 'tcp://10.79.251.22:80',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_PORT_6566_TCP': 'tcp://10.79.251.22:6566',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_PORT_6566_TCP_ADDR': '10.79.251.22',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_PORT_6566_TCP_PORT': '6566',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_PORT_6566_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_PORT_80_TCP': 'tcp://10.79.251.22:80',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_PORT_80_TCP_ADDR': '10.79.251.22',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_PORT_80_TCP_PORT': '80',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_PORT_80_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_SERVICE_HOST': '10.79.251.22',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_SERVICE_PORT': '80',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_SERVICE_PORT_GRPC': '6566',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_SERVICE_PORT_HTTP': '80',\n",
      " 'FEAST_RELEASE_KAFKA_PORT': 'tcp://10.79.251.121:9092',\n",
      " 'FEAST_RELEASE_KAFKA_PORT_9092_TCP': 'tcp://10.79.251.121:9092',\n",
      " 'FEAST_RELEASE_KAFKA_PORT_9092_TCP_ADDR': '10.79.251.121',\n",
      " 'FEAST_RELEASE_KAFKA_PORT_9092_TCP_PORT': '9092',\n",
      " 'FEAST_RELEASE_KAFKA_PORT_9092_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_KAFKA_SERVICE_HOST': '10.79.251.121',\n",
      " 'FEAST_RELEASE_KAFKA_SERVICE_PORT': '9092',\n",
      " 'FEAST_RELEASE_KAFKA_SERVICE_PORT_TCP_CLIENT': '9092',\n",
      " 'FEAST_RELEASE_POSTGRESQL_PORT': 'tcp://10.79.241.102:5432',\n",
      " 'FEAST_RELEASE_POSTGRESQL_PORT_5432_TCP': 'tcp://10.79.241.102:5432',\n",
      " 'FEAST_RELEASE_POSTGRESQL_PORT_5432_TCP_ADDR': '10.79.241.102',\n",
      " 'FEAST_RELEASE_POSTGRESQL_PORT_5432_TCP_PORT': '5432',\n",
      " 'FEAST_RELEASE_POSTGRESQL_PORT_5432_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_POSTGRESQL_SERVICE_HOST': '10.79.241.102',\n",
      " 'FEAST_RELEASE_POSTGRESQL_SERVICE_PORT': '5432',\n",
      " 'FEAST_RELEASE_POSTGRESQL_SERVICE_PORT_TCP_POSTGRESQL': '5432',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_PORT': 'tcp://10.79.241.200:6379',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_PORT_6379_TCP': 'tcp://10.79.241.200:6379',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_PORT_6379_TCP_ADDR': '10.79.241.200',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_PORT_6379_TCP_PORT': '6379',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_PORT_6379_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_SERVICE_HOST': '10.79.241.200',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_SERVICE_PORT': '6379',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_SERVICE_PORT_REDIS': '6379',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_PORT': 'tcp://10.79.240.115:6379',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_PORT_6379_TCP': 'tcp://10.79.240.115:6379',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_PORT_6379_TCP_ADDR': '10.79.240.115',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_PORT_6379_TCP_PORT': '6379',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_PORT_6379_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_SERVICE_HOST': '10.79.240.115',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_SERVICE_PORT': '6379',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_SERVICE_PORT_REDIS': '6379',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT': 'tcp://10.79.254.170:2181',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2181_TCP': 'tcp://10.79.254.170:2181',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2181_TCP_ADDR': '10.79.254.170',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2181_TCP_PORT': '2181',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2181_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2888_TCP': 'tcp://10.79.254.170:2888',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2888_TCP_ADDR': '10.79.254.170',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2888_TCP_PORT': '2888',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2888_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_3888_TCP': 'tcp://10.79.254.170:3888',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_3888_TCP_ADDR': '10.79.254.170',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_3888_TCP_PORT': '3888',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_3888_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_SERVICE_HOST': '10.79.254.170',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_SERVICE_PORT': '2181',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_SERVICE_PORT_FOLLOWER': '2888',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_SERVICE_PORT_TCP_CLIENT': '2181',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_SERVICE_PORT_TCP_ELECTION': '3888',\n",
      " 'FEAST_SERVING_URL': 'feast-release-feast-serving:6566',\n",
      " 'FEAST_SPARK_HOME': '/usr/local/spark',\n",
      " 'FEAST_SPARK_LAUNCHER': 'standalone',\n",
      " 'FEAST_SPARK_STAGING_LOCATION': 'file:///home/jovyan/spark_staging_location',\n",
      " 'FEAST_SPARK_STANDALONE_MASTER': 'local[*]'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "now = datetime.now() # current date and time\n",
    "date_time_str = now.strftime(\"%m-%d-%Y-%H-%M-%S\")\n",
    "print(date_time_str)\n",
    "pprint({key: value for key, value in os.environ.items() if key.startswith(\"FEAST_\")})\n",
    "staging_bucket = 'gs://my-feast-playground-s-11-35de9347/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feast is an open source project that collects anonymized usage statistics. To opt out or learn more see https://docs.feast.dev/v/master/advanced/telemetry\n"
     ]
    }
   ],
   "source": [
    "from feast import Client, Feature, Entity, ValueType, FeatureTable\n",
    "from feast.data_source import FileSource, KafkaSource\n",
    "from feast.data_format import ParquetFormat, AvroFormat\n",
    "#client = Client()\n",
    "\n",
    "client = Client(\n",
    "    core_url=\"feast-release-feast-core:6565\",\n",
    "    serving_url=\"feast-release-feast-serving:6566\",\n",
    "    spark_launcher=\"k8s\",\n",
    "    spark_staging_location=staging_bucket,\n",
    "    spark_k8s_namespace=\"default\",\n",
    "    executor_instances=2,\n",
    "    redis_host=\"feast-release-redis-headless\",\n",
    "    historical_feature_output_location=f\"{staging_bucket}historical\",\n",
    ")\n",
    "client.set_project(\"default\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare Features and Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "driver_id = Entity(name=\"driver_id\", description=\"Driver identifier\", value_type=ValueType.INT64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily updated features \n",
    "acc_rate = Feature(\"acc_rate\", ValueType.FLOAT)\n",
    "conv_rate = Feature(\"conv_rate\", ValueType.FLOAT)\n",
    "avg_daily_trips = Feature(\"avg_daily_trips\", ValueType.INT32)\n",
    "\n",
    "# Real-time updated features\n",
    "trips_today = Feature(\"trips_today\", ValueType.INT32)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://my-feast-playground-s-11-35de9347/03-25-2021-12-53-24\n"
     ]
    }
   ],
   "source": [
    "# Offline data will be stored in this location\n",
    "demo_data_location = staging_bucket+date_time_str\n",
    "print(demo_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_statistics_source_uri = os.path.join(demo_data_location, \"driver_statistics\")\n",
    "\n",
    "driver_statistics = FeatureTable(\n",
    "    name = \"driver_statistics\",\n",
    "    entities = [\"driver_id\"],\n",
    "    features = [\n",
    "        acc_rate,\n",
    "        conv_rate,\n",
    "        avg_daily_trips\n",
    "    ],\n",
    "    batch_source=FileSource(\n",
    "        event_timestamp_column=\"datetime\",\n",
    "        created_timestamp_column=\"created\",\n",
    "        file_format=ParquetFormat(),\n",
    "        file_url=driver_statistics_source_uri,\n",
    "        date_partition_column=\"date\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_trips_source_uri = os.path.join(demo_data_location, \"driver_trips\")\n",
    "\n",
    "driver_trips = FeatureTable(\n",
    "    name = \"driver_trips\",\n",
    "    entities = [\"driver_id\"],\n",
    "    features = [\n",
    "        trips_today\n",
    "    ],\n",
    "    batch_source=FileSource(\n",
    "        event_timestamp_column=\"datetime\",\n",
    "        created_timestamp_column=\"created\",\n",
    "        file_format=ParquetFormat(),\n",
    "        file_url=driver_trips_source_uri,\n",
    "        date_partition_column=\"date\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering entities and feature tables in Feast Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.apply(driver_id)\n",
    "client.apply(driver_statistics)\n",
    "client.apply(driver_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spec:\n",
      "  name: driver_statistics\n",
      "  entities:\n",
      "  - driver_id\n",
      "  features:\n",
      "  - name: avg_daily_trips\n",
      "    valueType: INT32\n",
      "  - name: conv_rate\n",
      "    valueType: FLOAT\n",
      "  - name: acc_rate\n",
      "    valueType: FLOAT\n",
      "  batchSource:\n",
      "    type: BATCH_FILE\n",
      "    eventTimestampColumn: datetime\n",
      "    datePartitionColumn: date\n",
      "    createdTimestampColumn: created\n",
      "    fileOptions:\n",
      "      fileFormat:\n",
      "        parquetFormat: {}\n",
      "      fileUrl: gs://my-feast-playground-s-11-35de9347/03-25-2021-12-53-24/driver_statistics\n",
      "meta:\n",
      "  createdTimestamp: '2021-03-25T12:53:30Z'\n",
      "\n",
      "spec:\n",
      "  name: driver_trips\n",
      "  entities:\n",
      "  - driver_id\n",
      "  features:\n",
      "  - name: trips_today\n",
      "    valueType: INT32\n",
      "  batchSource:\n",
      "    type: BATCH_FILE\n",
      "    eventTimestampColumn: datetime\n",
      "    datePartitionColumn: date\n",
      "    createdTimestampColumn: created\n",
      "    fileOptions:\n",
      "      fileFormat:\n",
      "        parquetFormat: {}\n",
      "      fileUrl: gs://my-feast-playground-s-11-35de9347/03-25-2021-12-53-24/driver_trips\n",
      "meta:\n",
      "  createdTimestamp: '2021-03-25T12:53:31Z'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(client.get_feature_table(\"driver_statistics\").to_yaml())\n",
    "print(client.get_feature_table(\"driver_trips\").to_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populating batch source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feast is agnostic to how the batch source is populated, as long as it complies to the Feature Table specification. Therefore, any existing ETL tools can be used for the purpose of data ingestion. Alternatively, you can also use Feast SDK to ingest a Panda Dataframe to the batch source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_entities():\n",
    "    return np.random.choice(999999, size=100, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trips(entities):\n",
    "    df = pd.DataFrame(columns=[\"driver_id\", \"trips_today\", \"datetime\", \"created\"])\n",
    "    df['driver_id'] = entities\n",
    "    df['trips_today'] = np.random.randint(0, 1000, size=100).astype(np.int32)\n",
    "    df['datetime'] = pd.to_datetime(\n",
    "            np.random.randint(\n",
    "                datetime(2020, 10, 10).timestamp(),\n",
    "                datetime(2020, 10, 20).timestamp(),\n",
    "                size=100),\n",
    "        unit=\"s\"\n",
    "    )\n",
    "    df['created'] = pd.to_datetime(datetime.now())\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stats(entities):\n",
    "    df = pd.DataFrame(columns=[\"driver_id\", \"conv_rate\", \"acc_rate\", \"avg_daily_trips\", \"datetime\", \"created\"])\n",
    "    df['driver_id'] = entities\n",
    "    df['conv_rate'] = np.random.random(size=100).astype(np.float32)\n",
    "    df['acc_rate'] = np.random.random(size=100).astype(np.float32)\n",
    "    df['avg_daily_trips'] = np.random.randint(0, 1000, size=100).astype(np.int32)\n",
    "    df['datetime'] = pd.to_datetime(\n",
    "            np.random.randint(\n",
    "                datetime(2020, 10, 10).timestamp(),\n",
    "                datetime(2020, 10, 20).timestamp(),\n",
    "                size=100),\n",
    "        unit=\"s\"\n",
    "    )\n",
    "    df['created'] = pd.to_datetime(datetime.now())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = generate_entities()\n",
    "stats_df = generate_stats(entities)\n",
    "trips_df = generate_trips(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing temporary file(s)...\n",
      "Data has been successfully ingested into FeatureTable batch source.\n",
      "Removing temporary file(s)...\n",
      "Data has been successfully ingested into FeatureTable batch source.\n"
     ]
    }
   ],
   "source": [
    "client.ingest(driver_statistics, stats_df)\n",
    "client.ingest(driver_trips, trips_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical Retrieval For Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a training dataset from offline feature tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "from pyarrow.parquet import ParquetDataset\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_id</th>\n",
       "      <th>event_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>768360</td>\n",
       "      <td>2020-10-18 19:16:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>951779</td>\n",
       "      <td>2020-10-19 12:31:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>705569</td>\n",
       "      <td>2020-10-19 09:34:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>918271</td>\n",
       "      <td>2020-10-19 17:48:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>542045</td>\n",
       "      <td>2020-10-19 10:03:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>206107</td>\n",
       "      <td>2020-10-19 15:07:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>853946</td>\n",
       "      <td>2020-10-18 18:49:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39913</td>\n",
       "      <td>2020-10-18 22:52:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900434</td>\n",
       "      <td>2020-10-18 10:31:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>154045</td>\n",
       "      <td>2020-10-19 13:04:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   driver_id     event_timestamp\n",
       "0     768360 2020-10-18 19:16:52\n",
       "1     951779 2020-10-19 12:31:19\n",
       "2     705569 2020-10-19 09:34:18\n",
       "3     918271 2020-10-19 17:48:33\n",
       "4     542045 2020-10-19 10:03:29\n",
       "5     206107 2020-10-19 15:07:53\n",
       "6     853946 2020-10-18 18:49:29\n",
       "7      39913 2020-10-18 22:52:13\n",
       "8     900434 2020-10-18 10:31:29\n",
       "9     154045 2020-10-19 13:04:20"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_with_timestamp = pd.DataFrame(columns=['driver_id', 'event_timestamp'])\n",
    "entities_with_timestamp['driver_id'] = np.random.choice(entities, 10, replace=False)\n",
    "entities_with_timestamp['event_timestamp'] = pd.to_datetime(np.random.randint(\n",
    "    datetime(2020, 10, 18).timestamp(),\n",
    "    datetime(2020, 10, 20).timestamp(),\n",
    "    size=10), unit='s')\n",
    "entities_with_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# get_historical_features will return immediately once the Spark job has been submitted succesfully.\n",
    "job = client.get_historical_features(\n",
    "    feature_refs=[\n",
    "        \"driver_statistics:avg_daily_trips\",\n",
    "        \"driver_statistics:conv_rate\",\n",
    "        \"driver_statistics:acc_rate\",\n",
    "        \"driver_trips:trips_today\"\n",
    "    ], \n",
    "    entity_source=entities_with_timestamp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://my-feast-playground-s-11-35de9347/historical/a7b3baea-6a33-4897-8596-c39d8a3e7e2e\n"
     ]
    }
   ],
   "source": [
    "# get_output_file_uri will block until the Spark job is completed.\n",
    "output_file_uri = job.get_output_file_uri()\n",
    "print(output_file_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_id</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>driver_statistics__avg_daily_trips</th>\n",
       "      <th>driver_statistics__conv_rate</th>\n",
       "      <th>driver_statistics__acc_rate</th>\n",
       "      <th>driver_trips__trips_today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>853946</td>\n",
       "      <td>2020-10-18 18:49:29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>542045</td>\n",
       "      <td>2020-10-19 10:03:29</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.140484</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>705569</td>\n",
       "      <td>2020-10-19 09:34:18</td>\n",
       "      <td>958.0</td>\n",
       "      <td>0.521007</td>\n",
       "      <td>0.386785</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>918271</td>\n",
       "      <td>2020-10-19 17:48:33</td>\n",
       "      <td>940.0</td>\n",
       "      <td>0.009663</td>\n",
       "      <td>0.909216</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154045</td>\n",
       "      <td>2020-10-19 13:04:20</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.968196</td>\n",
       "      <td>0.553506</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>951779</td>\n",
       "      <td>2020-10-19 12:31:19</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.172013</td>\n",
       "      <td>0.838158</td>\n",
       "      <td>772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>900434</td>\n",
       "      <td>2020-10-18 10:31:29</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.796095</td>\n",
       "      <td>0.775111</td>\n",
       "      <td>772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>206107</td>\n",
       "      <td>2020-10-19 15:07:53</td>\n",
       "      <td>492.0</td>\n",
       "      <td>0.269022</td>\n",
       "      <td>0.299133</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39913</td>\n",
       "      <td>2020-10-18 22:52:13</td>\n",
       "      <td>351.0</td>\n",
       "      <td>0.822276</td>\n",
       "      <td>0.992605</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>768360</td>\n",
       "      <td>2020-10-18 19:16:52</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.954050</td>\n",
       "      <td>0.094763</td>\n",
       "      <td>767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   driver_id     event_timestamp  driver_statistics__avg_daily_trips  \\\n",
       "0     853946 2020-10-18 18:49:29                                 NaN   \n",
       "1     542045 2020-10-19 10:03:29                               602.0   \n",
       "2     705569 2020-10-19 09:34:18                               958.0   \n",
       "3     918271 2020-10-19 17:48:33                               940.0   \n",
       "4     154045 2020-10-19 13:04:20                               440.0   \n",
       "5     951779 2020-10-19 12:31:19                                57.0   \n",
       "6     900434 2020-10-18 10:31:29                               220.0   \n",
       "7     206107 2020-10-19 15:07:53                               492.0   \n",
       "8      39913 2020-10-18 22:52:13                               351.0   \n",
       "9     768360 2020-10-18 19:16:52                               263.0   \n",
       "\n",
       "   driver_statistics__conv_rate  driver_statistics__acc_rate  \\\n",
       "0                           NaN                          NaN   \n",
       "1                      0.001133                     0.140484   \n",
       "2                      0.521007                     0.386785   \n",
       "3                      0.009663                     0.909216   \n",
       "4                      0.968196                     0.553506   \n",
       "5                      0.172013                     0.838158   \n",
       "6                      0.796095                     0.775111   \n",
       "7                      0.269022                     0.299133   \n",
       "8                      0.822276                     0.992605   \n",
       "9                      0.954050                     0.094763   \n",
       "\n",
       "   driver_trips__trips_today  \n",
       "0                        768  \n",
       "1                        306  \n",
       "2                         96  \n",
       "3                        638  \n",
       "4                        530  \n",
       "5                        772  \n",
       "6                        772  \n",
       "7                        522  \n",
       "8                        375  \n",
       "9                        767  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the remote training dataset\n",
    "time.sleep(10)\n",
    "parsed_uri = urlparse(output_file_uri)\n",
    "fs = gcsfs.GCSFileSystem()\n",
    "files = [\"gs://\" + path for path in fs.glob(output_file_uri + '/part-*')]\n",
    "ds = ParquetDataset(files, filesystem=fs)\n",
    "ds.read().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The retrieved result can now be used for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating Online Storage with Batch Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to populate the online storage, we can use Feast SDK to start a Spark batch job which will extract the features from the batch source, then load the features to an online store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "time.sleep(5)\n",
    "job = client.start_offline_to_online_ingestion(\n",
    "    driver_statistics,\n",
    "    datetime(2020, 10, 10),\n",
    "    datetime(2020, 10, 20)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will take some time before the Spark Job is completed\n",
    "time.sleep(15)\n",
    "job.get_status()\n",
    "time.sleep(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the job is completed, the SDK can be used to retrieve the result from the online store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_sample = np.random.choice(entities, 10, replace=False)\n",
    "entities_sample = [{\"driver_id\": e} for e in entities_sample]\n",
    "entities_sample\n",
    "time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'driver_statistics:avg_daily_trips': [None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None],\n",
       " 'driver_id': [601619,\n",
       "  429198,\n",
       "  78691,\n",
       "  705569,\n",
       "  486634,\n",
       "  265905,\n",
       "  912559,\n",
       "  184790,\n",
       "  37658,\n",
       "  279076]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(15)\n",
    "\n",
    "features = client.get_online_features(\n",
    "    feature_refs=[\"driver_statistics:avg_daily_trips\"],\n",
    "    entity_rows=entities_sample).to_dict()\n",
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_statistics:avg_daily_trips</th>\n",
       "      <th>driver_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>601619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>429198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>78691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>705569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>486634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>265905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>912559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>184790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>37658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>279076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  driver_statistics:avg_daily_trips  driver_id\n",
       "0                              None     601619\n",
       "1                              None     429198\n",
       "2                              None      78691\n",
       "3                              None     705569\n",
       "4                              None     486634\n",
       "5                              None     265905\n",
       "6                              None     912559\n",
       "7                              None     184790\n",
       "8                              None      37658\n",
       "9                              None     279076"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
