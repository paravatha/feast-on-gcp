{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal Ride Hailing Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart your Kernel after installing these packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install protobuf gcsfs feast -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports and Feast Client initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FEAST_CORE_URL': 'feast-release-feast-core:6565',\n",
      " 'FEAST_HISTORICAL_SERVING_URL': 'feast-release-feast-batch-serving:6566',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT': 'tcp://10.79.240.204:80',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_6565_TCP': 'tcp://10.79.240.204:6565',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_6565_TCP_ADDR': '10.79.240.204',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_6565_TCP_PORT': '6565',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_6565_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_80_TCP': 'tcp://10.79.240.204:80',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_80_TCP_ADDR': '10.79.240.204',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_80_TCP_PORT': '80',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_80_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_FEAST_CORE_SERVICE_HOST': '10.79.240.204',\n",
      " 'FEAST_RELEASE_FEAST_CORE_SERVICE_PORT': '80',\n",
      " 'FEAST_RELEASE_FEAST_CORE_SERVICE_PORT_GRPC': '6565',\n",
      " 'FEAST_RELEASE_FEAST_CORE_SERVICE_PORT_HTTP': '80',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT': 'tcp://10.79.248.135:80',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_6568_TCP': 'tcp://10.79.248.135:6568',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_6568_TCP_ADDR': '10.79.248.135',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_6568_TCP_PORT': '6568',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_6568_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_80_TCP': 'tcp://10.79.248.135:80',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_80_TCP_ADDR': '10.79.248.135',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_80_TCP_PORT': '80',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_80_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_SERVICE_HOST': '10.79.248.135',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_SERVICE_PORT': '80',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_SERVICE_PORT_GRPC': '6568',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_SERVICE_PORT_HTTP': '80',\n",
      " 'FEAST_RELEASE_FEAST_ONLINE_SERVING_PORT': 'tcp://10.79.242.233:80',\n",
      " 'FEAST_RELEASE_FEAST_ONLINE_SERVING_PORT_6566_TCP': 'tcp://10.79.242.233:6566',\n",
      " 'FEAST_RELEASE_FEAST_ONLINE_SERVING_PORT_6566_TCP_ADDR': '10.79.242.233',\n",
      " 'FEAST_RELEASE_FEAST_ONLINE_SERVING_PORT_6566_TCP_PORT': '6566',\n",
      " 'FEAST_RELEASE_FEAST_ONLINE_SERVING_PORT_6566_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_FEAST_ONLINE_SERVING_PORT_80_TCP': 'tcp://10.79.242.233:80',\n",
      " 'FEAST_RELEASE_FEAST_ONLINE_SERVING_PORT_80_TCP_ADDR': '10.79.242.233',\n",
      " 'FEAST_RELEASE_FEAST_ONLINE_SERVING_PORT_80_TCP_PORT': '80',\n",
      " 'FEAST_RELEASE_FEAST_ONLINE_SERVING_PORT_80_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_FEAST_ONLINE_SERVING_SERVICE_HOST': '10.79.242.233',\n",
      " 'FEAST_RELEASE_FEAST_ONLINE_SERVING_SERVICE_PORT': '80',\n",
      " 'FEAST_RELEASE_FEAST_ONLINE_SERVING_SERVICE_PORT_GRPC': '6566',\n",
      " 'FEAST_RELEASE_FEAST_ONLINE_SERVING_SERVICE_PORT_HTTP': '80',\n",
      " 'FEAST_RELEASE_GRAFANA_PORT': 'tcp://10.79.243.100:80',\n",
      " 'FEAST_RELEASE_GRAFANA_PORT_80_TCP': 'tcp://10.79.243.100:80',\n",
      " 'FEAST_RELEASE_GRAFANA_PORT_80_TCP_ADDR': '10.79.243.100',\n",
      " 'FEAST_RELEASE_GRAFANA_PORT_80_TCP_PORT': '80',\n",
      " 'FEAST_RELEASE_GRAFANA_PORT_80_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_GRAFANA_SERVICE_HOST': '10.79.243.100',\n",
      " 'FEAST_RELEASE_GRAFANA_SERVICE_PORT': '80',\n",
      " 'FEAST_RELEASE_GRAFANA_SERVICE_PORT_SERVICE': '80',\n",
      " 'FEAST_RELEASE_KAFKA_PORT': 'tcp://10.79.250.132:9092',\n",
      " 'FEAST_RELEASE_KAFKA_PORT_9092_TCP': 'tcp://10.79.250.132:9092',\n",
      " 'FEAST_RELEASE_KAFKA_PORT_9092_TCP_ADDR': '10.79.250.132',\n",
      " 'FEAST_RELEASE_KAFKA_PORT_9092_TCP_PORT': '9092',\n",
      " 'FEAST_RELEASE_KAFKA_PORT_9092_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_KAFKA_SERVICE_HOST': '10.79.250.132',\n",
      " 'FEAST_RELEASE_KAFKA_SERVICE_PORT': '9092',\n",
      " 'FEAST_RELEASE_KAFKA_SERVICE_PORT_TCP_CLIENT': '9092',\n",
      " 'FEAST_RELEASE_KUBE_STATE_METRICS_PORT': 'tcp://10.79.242.79:8080',\n",
      " 'FEAST_RELEASE_KUBE_STATE_METRICS_PORT_8080_TCP': 'tcp://10.79.242.79:8080',\n",
      " 'FEAST_RELEASE_KUBE_STATE_METRICS_PORT_8080_TCP_ADDR': '10.79.242.79',\n",
      " 'FEAST_RELEASE_KUBE_STATE_METRICS_PORT_8080_TCP_PORT': '8080',\n",
      " 'FEAST_RELEASE_KUBE_STATE_METRICS_PORT_8080_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_KUBE_STATE_METRICS_SERVICE_HOST': '10.79.242.79',\n",
      " 'FEAST_RELEASE_KUBE_STATE_METRICS_SERVICE_PORT': '8080',\n",
      " 'FEAST_RELEASE_KUBE_STATE_METRICS_SERVICE_PORT_HTTP': '8080',\n",
      " 'FEAST_RELEASE_POSTGRESQL_PORT': 'tcp://10.79.254.91:5432',\n",
      " 'FEAST_RELEASE_POSTGRESQL_PORT_5432_TCP': 'tcp://10.79.254.91:5432',\n",
      " 'FEAST_RELEASE_POSTGRESQL_PORT_5432_TCP_ADDR': '10.79.254.91',\n",
      " 'FEAST_RELEASE_POSTGRESQL_PORT_5432_TCP_PORT': '5432',\n",
      " 'FEAST_RELEASE_POSTGRESQL_PORT_5432_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_POSTGRESQL_SERVICE_HOST': '10.79.254.91',\n",
      " 'FEAST_RELEASE_POSTGRESQL_SERVICE_PORT': '5432',\n",
      " 'FEAST_RELEASE_POSTGRESQL_SERVICE_PORT_TCP_POSTGRESQL': '5432',\n",
      " 'FEAST_RELEASE_PROMETHEUS_ALERTMANAGER_PORT': 'tcp://10.79.241.67:80',\n",
      " 'FEAST_RELEASE_PROMETHEUS_ALERTMANAGER_PORT_80_TCP': 'tcp://10.79.241.67:80',\n",
      " 'FEAST_RELEASE_PROMETHEUS_ALERTMANAGER_PORT_80_TCP_ADDR': '10.79.241.67',\n",
      " 'FEAST_RELEASE_PROMETHEUS_ALERTMANAGER_PORT_80_TCP_PORT': '80',\n",
      " 'FEAST_RELEASE_PROMETHEUS_ALERTMANAGER_PORT_80_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_PROMETHEUS_ALERTMANAGER_SERVICE_HOST': '10.79.241.67',\n",
      " 'FEAST_RELEASE_PROMETHEUS_ALERTMANAGER_SERVICE_PORT': '80',\n",
      " 'FEAST_RELEASE_PROMETHEUS_ALERTMANAGER_SERVICE_PORT_HTTP': '80',\n",
      " 'FEAST_RELEASE_PROMETHEUS_PUSHGATEWAY_PORT': 'tcp://10.79.248.56:9091',\n",
      " 'FEAST_RELEASE_PROMETHEUS_PUSHGATEWAY_PORT_9091_TCP': 'tcp://10.79.248.56:9091',\n",
      " 'FEAST_RELEASE_PROMETHEUS_PUSHGATEWAY_PORT_9091_TCP_ADDR': '10.79.248.56',\n",
      " 'FEAST_RELEASE_PROMETHEUS_PUSHGATEWAY_PORT_9091_TCP_PORT': '9091',\n",
      " 'FEAST_RELEASE_PROMETHEUS_PUSHGATEWAY_PORT_9091_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_PROMETHEUS_PUSHGATEWAY_SERVICE_HOST': '10.79.248.56',\n",
      " 'FEAST_RELEASE_PROMETHEUS_PUSHGATEWAY_SERVICE_PORT': '9091',\n",
      " 'FEAST_RELEASE_PROMETHEUS_PUSHGATEWAY_SERVICE_PORT_HTTP': '9091',\n",
      " 'FEAST_RELEASE_PROMETHEUS_SERVER_PORT': 'tcp://10.79.255.121:80',\n",
      " 'FEAST_RELEASE_PROMETHEUS_SERVER_PORT_80_TCP': 'tcp://10.79.255.121:80',\n",
      " 'FEAST_RELEASE_PROMETHEUS_SERVER_PORT_80_TCP_ADDR': '10.79.255.121',\n",
      " 'FEAST_RELEASE_PROMETHEUS_SERVER_PORT_80_TCP_PORT': '80',\n",
      " 'FEAST_RELEASE_PROMETHEUS_SERVER_PORT_80_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_PROMETHEUS_SERVER_SERVICE_HOST': '10.79.255.121',\n",
      " 'FEAST_RELEASE_PROMETHEUS_SERVER_SERVICE_PORT': '80',\n",
      " 'FEAST_RELEASE_PROMETHEUS_SERVER_SERVICE_PORT_HTTP': '80',\n",
      " 'FEAST_RELEASE_PROMETHEUS_STATSD_EXPORTER_PORT': 'tcp://10.79.254.44:9102',\n",
      " 'FEAST_RELEASE_PROMETHEUS_STATSD_EXPORTER_PORT_9102_TCP': 'tcp://10.79.254.44:9102',\n",
      " 'FEAST_RELEASE_PROMETHEUS_STATSD_EXPORTER_PORT_9102_TCP_ADDR': '10.79.254.44',\n",
      " 'FEAST_RELEASE_PROMETHEUS_STATSD_EXPORTER_PORT_9102_TCP_PORT': '9102',\n",
      " 'FEAST_RELEASE_PROMETHEUS_STATSD_EXPORTER_PORT_9102_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_PROMETHEUS_STATSD_EXPORTER_PORT_9125_TCP': 'tcp://10.79.254.44:9125',\n",
      " 'FEAST_RELEASE_PROMETHEUS_STATSD_EXPORTER_PORT_9125_TCP_ADDR': '10.79.254.44',\n",
      " 'FEAST_RELEASE_PROMETHEUS_STATSD_EXPORTER_PORT_9125_TCP_PORT': '9125',\n",
      " 'FEAST_RELEASE_PROMETHEUS_STATSD_EXPORTER_PORT_9125_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_PROMETHEUS_STATSD_EXPORTER_SERVICE_HOST': '10.79.254.44',\n",
      " 'FEAST_RELEASE_PROMETHEUS_STATSD_EXPORTER_SERVICE_PORT': '9102',\n",
      " 'FEAST_RELEASE_PROMETHEUS_STATSD_EXPORTER_SERVICE_PORT_METRICS': '9102',\n",
      " 'FEAST_RELEASE_PROMETHEUS_STATSD_EXPORTER_SERVICE_PORT_STATSD_TCP': '9125',\n",
      " 'FEAST_RELEASE_PROMETHEUS_STATSD_EXPORTER_UDP_PORT': 'udp://10.79.245.194:9125',\n",
      " 'FEAST_RELEASE_PROMETHEUS_STATSD_EXPORTER_UDP_PORT_9125_UDP': 'udp://10.79.245.194:9125',\n",
      " 'FEAST_RELEASE_PROMETHEUS_STATSD_EXPORTER_UDP_PORT_9125_UDP_ADDR': '10.79.245.194',\n",
      " 'FEAST_RELEASE_PROMETHEUS_STATSD_EXPORTER_UDP_PORT_9125_UDP_PORT': '9125',\n",
      " 'FEAST_RELEASE_PROMETHEUS_STATSD_EXPORTER_UDP_PORT_9125_UDP_PROTO': 'udp',\n",
      " 'FEAST_RELEASE_PROMETHEUS_STATSD_EXPORTER_UDP_SERVICE_HOST': '10.79.245.194',\n",
      " 'FEAST_RELEASE_PROMETHEUS_STATSD_EXPORTER_UDP_SERVICE_PORT': '9125',\n",
      " 'FEAST_RELEASE_PROMETHEUS_STATSD_EXPORTER_UDP_SERVICE_PORT_STATSD_UDP': '9125',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_PORT': 'tcp://10.79.251.126:6379',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_PORT_6379_TCP': 'tcp://10.79.251.126:6379',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_PORT_6379_TCP_ADDR': '10.79.251.126',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_PORT_6379_TCP_PORT': '6379',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_PORT_6379_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_SERVICE_HOST': '10.79.251.126',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_SERVICE_PORT': '6379',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_SERVICE_PORT_REDIS': '6379',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_PORT': 'tcp://10.79.243.73:6379',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_PORT_6379_TCP': 'tcp://10.79.243.73:6379',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_PORT_6379_TCP_ADDR': '10.79.243.73',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_PORT_6379_TCP_PORT': '6379',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_PORT_6379_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_SERVICE_HOST': '10.79.243.73',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_SERVICE_PORT': '6379',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_SERVICE_PORT_REDIS': '6379',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT': 'tcp://10.79.248.72:2181',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2181_TCP': 'tcp://10.79.248.72:2181',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2181_TCP_ADDR': '10.79.248.72',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2181_TCP_PORT': '2181',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2181_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2888_TCP': 'tcp://10.79.248.72:2888',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2888_TCP_ADDR': '10.79.248.72',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2888_TCP_PORT': '2888',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2888_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_3888_TCP': 'tcp://10.79.248.72:3888',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_3888_TCP_ADDR': '10.79.248.72',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_3888_TCP_PORT': '3888',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_3888_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_SERVICE_HOST': '10.79.248.72',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_SERVICE_PORT': '2181',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_SERVICE_PORT_FOLLOWER': '2888',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_SERVICE_PORT_TCP_CLIENT': '2181',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_SERVICE_PORT_TCP_ELECTION': '3888',\n",
      " 'FEAST_SERVING_URL': 'feast-release-feast-online-serving:6566',\n",
      " 'FEAST_SPARK_HOME': '/usr/local/spark',\n",
      " 'FEAST_SPARK_LAUNCHER': 'standalone',\n",
      " 'FEAST_SPARK_STANDALONE_MASTER': 'local[*]'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "pprint({key: value for key, value in os.environ.items() if key.startswith(\"FEAST_\")})\n",
    "import os\n",
    "staging_bucket = 'gs://my-feast-playground-s-11-cf9589f2'\n",
    "from feast import Client, Feature, Entity, ValueType, FeatureTable\n",
    "from feast.data_source import FileSource, KafkaSource\n",
    "from feast.data_format import ParquetFormat, AvroFormat\n",
    "#client = Client()\n",
    "\n",
    "client = Client(\n",
    "    core_url=\"feast-release-feast-core:6565\",\n",
    "    serving_url=\"feast-release-feast-online-serving:6566\",\n",
    "    spark_launcher=\"k8s\",\n",
    "    spark_staging_location=staging_bucket,\n",
    "    spark_k8s_namespace=\"sparkop\",\n",
    "    redis_host=\"feast-release-redis-headless\",\n",
    "    historical_feature_output_location=f\"{staging_bucket}historical\",\n",
    ")\n",
    "client.set_project(\"playground-s-11-cf9589f2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare Features and Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "driver_id = Entity(name=\"driver_id\", description=\"Driver identifier\", value_type=ValueType.INT64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily updated features \n",
    "acc_rate = Feature(\"acc_rate\", ValueType.FLOAT)\n",
    "conv_rate = Feature(\"conv_rate\", ValueType.FLOAT)\n",
    "avg_daily_trips = Feature(\"avg_daily_trips\", ValueType.INT32)\n",
    "\n",
    "# Real-time updated features\n",
    "trips_today = Feature(\"trips_today\", ValueType.INT32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://my-feast-playground-s-11-cf9589f2/test_data/feb28_11_10pm\n"
     ]
    }
   ],
   "source": [
    "# Offline data will be stored in this location\n",
    "demo_data_location = os.path.join(os.getenv(\"FEAST_SPARK_STAGING_LOCATION\", staging_bucket), \"test_data/feb28_11_10pm\")\n",
    "print(demo_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_statistics_source_uri = os.path.join(demo_data_location, \"driver_statistics\")\n",
    "\n",
    "driver_statistics = FeatureTable(\n",
    "    name = \"driver_statistics\",\n",
    "    entities = [\"driver_id\"],\n",
    "    features = [\n",
    "        acc_rate,\n",
    "        conv_rate,\n",
    "        avg_daily_trips\n",
    "    ],\n",
    "    batch_source=FileSource(\n",
    "        event_timestamp_column=\"datetime\",\n",
    "        created_timestamp_column=\"created\",\n",
    "        file_format=ParquetFormat(),\n",
    "        file_url=driver_statistics_source_uri,\n",
    "        date_partition_column=\"date\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_trips_source_uri = os.path.join(demo_data_location, \"driver_trips\")\n",
    "\n",
    "\n",
    "driver_trips = FeatureTable(\n",
    "    name = \"driver_trips\",\n",
    "    entities = [\"driver_id\"],\n",
    "    features = [\n",
    "        trips_today\n",
    "    ],\n",
    "    batch_source=FileSource(\n",
    "        event_timestamp_column=\"datetime\",\n",
    "        created_timestamp_column=\"created\",\n",
    "        file_format=ParquetFormat(),\n",
    "        file_url=driver_trips_source_uri,\n",
    "        date_partition_column=\"date\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering entities and feature tables in Feast Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.apply(driver_id)\n",
    "client.apply(driver_statistics)\n",
    "client.apply(driver_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RpcError",
     "evalue": "invalid value for project resource, playground-s-11-cf9589f2: argument must only contain alphanumeric characters and underscores.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/feast/client.py\u001b[0m in \u001b[0;36mget_feature_table\u001b[0;34m(self, name, project)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m             get_feature_table_response = self._core_service.GetFeatureTable(\n\u001b[0m\u001b[1;32m    753\u001b[0m                 \u001b[0mGetFeatureTableRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    825\u001b[0m                                       wait_for_ready, compression)\n\u001b[0;32m--> 826\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INTERNAL\n\tdetails = \"invalid value for project resource, playground-s-11-cf9589f2: argument must only contain alphanumeric characters and underscores.\"\n\tdebug_error_string = \"{\"created\":\"@1614577106.819763911\",\"description\":\"Error received from peer ipv4:10.79.240.204:6565\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1061,\"grpc_message\":\"invalid value for project resource, playground-s-11-cf9589f2: argument must only contain alphanumeric characters and underscores.\",\"grpc_status\":13}\"\n>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRpcError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-63664612e580>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"driver_statistics\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_yaml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"driver_trips\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_yaml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/feast/client.py\u001b[0m in \u001b[0;36mget_feature_table\u001b[0;34m(self, name, project)\u001b[0m\n\u001b[1;32m    755\u001b[0m             )  # type: GetFeatureTableResponse\n\u001b[1;32m    756\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mFeatureTable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_feature_table_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRpcError\u001b[0m: invalid value for project resource, playground-s-11-cf9589f2: argument must only contain alphanumeric characters and underscores."
     ]
    }
   ],
   "source": [
    "print(client.get_feature_table(\"driver_statistics\").to_yaml())\n",
    "print(client.get_feature_table(\"driver_trips\").to_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populating batch source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feast is agnostic to how the batch source is populated, as long as it complies to the Feature Table specification. Therefore, any existing ETL tools can be used for the purpose of data ingestion. Alternatively, you can also use Feast SDK to ingest a Panda Dataframe to the batch source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_entities():\n",
    "    return np.random.choice(999999, size=100, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trips(entities):\n",
    "    df = pd.DataFrame(columns=[\"driver_id\", \"trips_today\", \"datetime\", \"created\"])\n",
    "    df['driver_id'] = entities\n",
    "    df['trips_today'] = np.random.randint(0, 1000, size=100).astype(np.int32)\n",
    "    df['datetime'] = pd.to_datetime(\n",
    "            np.random.randint(\n",
    "                datetime(2020, 10, 10).timestamp(),\n",
    "                datetime(2020, 10, 20).timestamp(),\n",
    "                size=100),\n",
    "        unit=\"s\"\n",
    "    )\n",
    "    df['created'] = pd.to_datetime(datetime.now())\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stats(entities):\n",
    "    df = pd.DataFrame(columns=[\"driver_id\", \"conv_rate\", \"acc_rate\", \"avg_daily_trips\", \"datetime\", \"created\"])\n",
    "    df['driver_id'] = entities\n",
    "    df['conv_rate'] = np.random.random(size=100).astype(np.float32)\n",
    "    df['acc_rate'] = np.random.random(size=100).astype(np.float32)\n",
    "    df['avg_daily_trips'] = np.random.randint(0, 1000, size=100).astype(np.int32)\n",
    "    df['datetime'] = pd.to_datetime(\n",
    "            np.random.randint(\n",
    "                datetime(2020, 10, 10).timestamp(),\n",
    "                datetime(2020, 10, 20).timestamp(),\n",
    "                size=100),\n",
    "        unit=\"s\"\n",
    "    )\n",
    "    df['created'] = pd.to_datetime(datetime.now())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = generate_entities()\n",
    "stats_df = generate_stats(entities)\n",
    "trips_df = generate_trips(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.ingest(driver_statistics, stats_df)\n",
    "client.ingest(driver_trips, trips_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical Retrieval For Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a training dataset from offline feature tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "from pyarrow.parquet import ParquetDataset\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_with_timestamp = pd.DataFrame(columns=['driver_id', 'event_timestamp'])\n",
    "entities_with_timestamp['driver_id'] = np.random.choice(entities, 10, replace=False)\n",
    "entities_with_timestamp['event_timestamp'] = pd.to_datetime(np.random.randint(\n",
    "    datetime(2020, 10, 18).timestamp(),\n",
    "    datetime(2020, 10, 20).timestamp(),\n",
    "    size=10), unit='s')\n",
    "entities_with_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_historical_features will return immediately once the Spark job has been submitted succesfully.\n",
    "job = client.get_historical_features(\n",
    "    feature_refs=[\n",
    "        \"driver_statistics:avg_daily_trips\",\n",
    "        \"driver_statistics:conv_rate\",\n",
    "        \"driver_statistics:acc_rate\",\n",
    "        \"driver_trips:trips_today\"\n",
    "    ], \n",
    "    entity_source=entities_with_timestamp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_output_file_uri will block until the Spark job is completed.\n",
    "output_file_uri = job.get_output_file_uri()\n",
    "print(output_file_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the remote training dataset\n",
    "\n",
    "parsed_uri = urlparse(output_file_uri)\n",
    "fs = gcsfs.GCSFileSystem()\n",
    "files = [\"gs://\" + path for path in fs.glob(output_file_uri + '/part-*')]\n",
    "ds = ParquetDataset(files, filesystem=fs)\n",
    "ds.read().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The retrieved result can now be used for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating Online Storage with Batch Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to populate the online storage, we can use Feast SDK to start a Spark batch job which will extract the features from the batch source, then load the features to an online store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = client.start_offline_to_online_ingestion(\n",
    "    driver_statistics,\n",
    "    datetime(2020, 10, 10),\n",
    "    datetime(2020, 10, 20)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will take some time before the Spark Job is completed\n",
    "job.get_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the job is completed, the SDK can be used to retrieve the result from the online store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_sample = np.random.choice(entities, 10, replace=False)\n",
    "entities_sample = [{\"driver_id\": e} for e in entities_sample]\n",
    "entities_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = client.get_online_features(\n",
    "    feature_refs=[\"driver_statistics:avg_daily_trips\"],\n",
    "    entity_rows=entities_sample).to_dict()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
