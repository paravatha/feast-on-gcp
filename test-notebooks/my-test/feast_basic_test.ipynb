{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal Ride Hailing Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart your Kernel after installing these packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install protobuf gcsfs feast -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports and Feast Client initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FEAST_CORE_URL': 'feast-release-feast-core:6565',\n",
      " 'FEAST_HISTORICAL_FEATURE_OUTPUT_LOCATION': 'file:///home/jovyan/historical_feature_output',\n",
      " 'FEAST_HISTORICAL_SERVING_URL': 'feast-release-feast-batch-serving:6566',\n",
      " 'FEAST_REDIS_HOST': 'feast-release-redis-master',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT': 'tcp://10.79.242.197:80',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_6565_TCP': 'tcp://10.79.242.197:6565',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_6565_TCP_ADDR': '10.79.242.197',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_6565_TCP_PORT': '6565',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_6565_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_80_TCP': 'tcp://10.79.242.197:80',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_80_TCP_ADDR': '10.79.242.197',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_80_TCP_PORT': '80',\n",
      " 'FEAST_RELEASE_FEAST_CORE_PORT_80_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_FEAST_CORE_SERVICE_HOST': '10.79.242.197',\n",
      " 'FEAST_RELEASE_FEAST_CORE_SERVICE_PORT': '80',\n",
      " 'FEAST_RELEASE_FEAST_CORE_SERVICE_PORT_GRPC': '6565',\n",
      " 'FEAST_RELEASE_FEAST_CORE_SERVICE_PORT_HTTP': '80',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT': 'tcp://10.79.244.207:80',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_6568_TCP': 'tcp://10.79.244.207:6568',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_6568_TCP_ADDR': '10.79.244.207',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_6568_TCP_PORT': '6568',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_6568_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_80_TCP': 'tcp://10.79.244.207:80',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_80_TCP_ADDR': '10.79.244.207',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_80_TCP_PORT': '80',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_PORT_80_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_SERVICE_HOST': '10.79.244.207',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_SERVICE_PORT': '80',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_SERVICE_PORT_GRPC': '6568',\n",
      " 'FEAST_RELEASE_FEAST_JOBSERVICE_SERVICE_PORT_HTTP': '80',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_PORT': 'tcp://10.79.244.187:80',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_PORT_6566_TCP': 'tcp://10.79.244.187:6566',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_PORT_6566_TCP_ADDR': '10.79.244.187',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_PORT_6566_TCP_PORT': '6566',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_PORT_6566_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_PORT_80_TCP': 'tcp://10.79.244.187:80',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_PORT_80_TCP_ADDR': '10.79.244.187',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_PORT_80_TCP_PORT': '80',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_PORT_80_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_SERVICE_HOST': '10.79.244.187',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_SERVICE_PORT': '80',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_SERVICE_PORT_GRPC': '6566',\n",
      " 'FEAST_RELEASE_FEAST_SERVING_SERVICE_PORT_HTTP': '80',\n",
      " 'FEAST_RELEASE_KAFKA_PORT': 'tcp://10.79.244.26:9092',\n",
      " 'FEAST_RELEASE_KAFKA_PORT_9092_TCP': 'tcp://10.79.244.26:9092',\n",
      " 'FEAST_RELEASE_KAFKA_PORT_9092_TCP_ADDR': '10.79.244.26',\n",
      " 'FEAST_RELEASE_KAFKA_PORT_9092_TCP_PORT': '9092',\n",
      " 'FEAST_RELEASE_KAFKA_PORT_9092_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_KAFKA_SERVICE_HOST': '10.79.244.26',\n",
      " 'FEAST_RELEASE_KAFKA_SERVICE_PORT': '9092',\n",
      " 'FEAST_RELEASE_KAFKA_SERVICE_PORT_TCP_CLIENT': '9092',\n",
      " 'FEAST_RELEASE_POSTGRESQL_PORT': 'tcp://10.79.240.249:5432',\n",
      " 'FEAST_RELEASE_POSTGRESQL_PORT_5432_TCP': 'tcp://10.79.240.249:5432',\n",
      " 'FEAST_RELEASE_POSTGRESQL_PORT_5432_TCP_ADDR': '10.79.240.249',\n",
      " 'FEAST_RELEASE_POSTGRESQL_PORT_5432_TCP_PORT': '5432',\n",
      " 'FEAST_RELEASE_POSTGRESQL_PORT_5432_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_POSTGRESQL_SERVICE_HOST': '10.79.240.249',\n",
      " 'FEAST_RELEASE_POSTGRESQL_SERVICE_PORT': '5432',\n",
      " 'FEAST_RELEASE_POSTGRESQL_SERVICE_PORT_TCP_POSTGRESQL': '5432',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_PORT': 'tcp://10.79.250.145:6379',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_PORT_6379_TCP': 'tcp://10.79.250.145:6379',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_PORT_6379_TCP_ADDR': '10.79.250.145',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_PORT_6379_TCP_PORT': '6379',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_PORT_6379_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_SERVICE_HOST': '10.79.250.145',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_SERVICE_PORT': '6379',\n",
      " 'FEAST_RELEASE_REDIS_MASTER_SERVICE_PORT_REDIS': '6379',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_PORT': 'tcp://10.79.246.72:6379',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_PORT_6379_TCP': 'tcp://10.79.246.72:6379',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_PORT_6379_TCP_ADDR': '10.79.246.72',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_PORT_6379_TCP_PORT': '6379',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_PORT_6379_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_SERVICE_HOST': '10.79.246.72',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_SERVICE_PORT': '6379',\n",
      " 'FEAST_RELEASE_REDIS_SLAVE_SERVICE_PORT_REDIS': '6379',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT': 'tcp://10.79.244.80:2181',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2181_TCP': 'tcp://10.79.244.80:2181',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2181_TCP_ADDR': '10.79.244.80',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2181_TCP_PORT': '2181',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2181_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2888_TCP': 'tcp://10.79.244.80:2888',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2888_TCP_ADDR': '10.79.244.80',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2888_TCP_PORT': '2888',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_2888_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_3888_TCP': 'tcp://10.79.244.80:3888',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_3888_TCP_ADDR': '10.79.244.80',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_3888_TCP_PORT': '3888',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_PORT_3888_TCP_PROTO': 'tcp',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_SERVICE_HOST': '10.79.244.80',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_SERVICE_PORT': '2181',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_SERVICE_PORT_FOLLOWER': '2888',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_SERVICE_PORT_TCP_CLIENT': '2181',\n",
      " 'FEAST_RELEASE_ZOOKEEPER_SERVICE_PORT_TCP_ELECTION': '3888',\n",
      " 'FEAST_SERVING_URL': 'feast-release-feast-serving:6566',\n",
      " 'FEAST_SPARK_HOME': '/usr/local/spark',\n",
      " 'FEAST_SPARK_LAUNCHER': 'standalone',\n",
      " 'FEAST_SPARK_STAGING_LOCATION': 'file:///home/jovyan/spark_staging_location',\n",
      " 'FEAST_SPARK_STANDALONE_MASTER': 'local[*]'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "pprint({key: value for key, value in os.environ.items() if key.startswith(\"FEAST_\")})\n",
    "import os\n",
    "staging_bucket = 'gs://my-feast-playground-s-11-4744ea70/'\n",
    "from feast import Client, Feature, Entity, ValueType, FeatureTable\n",
    "from feast.data_source import FileSource, KafkaSource\n",
    "from feast.data_format import ParquetFormat, AvroFormat\n",
    "#client = Client()\n",
    "\n",
    "client = Client(\n",
    "    core_url=\"feast-release-feast-core:6565\",\n",
    "    serving_url=\"feast-release-feast-serving:6566\",\n",
    "    spark_launcher=\"k8s\",\n",
    "    spark_staging_location=staging_bucket,\n",
    "    spark_k8s_namespace=\"default\",\n",
    "    executor_instances=2,\n",
    "    redis_host=\"feast-release-redis-headless\",\n",
    "    historical_feature_output_location=f\"{staging_bucket}historical\",\n",
    ")\n",
    "client.set_project(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare Features and Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "driver_id = Entity(name=\"driver_id\", description=\"Driver identifier\", value_type=ValueType.INT64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily updated features \n",
    "acc_rate = Feature(\"acc_rate\", ValueType.FLOAT)\n",
    "conv_rate = Feature(\"conv_rate\", ValueType.FLOAT)\n",
    "avg_daily_trips = Feature(\"avg_daily_trips\", ValueType.INT32)\n",
    "\n",
    "# Real-time updated features\n",
    "trips_today = Feature(\"trips_today\", ValueType.INT32)\n",
    "import time\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://my-feast-playground-s-11-4744ea70/test_data/feb28_11_10pm\n"
     ]
    }
   ],
   "source": [
    "# Offline data will be stored in this location\n",
    "demo_data_location = \"gs://my-feast-playground-s-11-4744ea70/test_data/feb28_11_10pm\"\n",
    "print(demo_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_statistics_source_uri = os.path.join(demo_data_location, \"driver_statistics\")\n",
    "\n",
    "driver_statistics = FeatureTable(\n",
    "    name = \"driver_statistics\",\n",
    "    entities = [\"driver_id\"],\n",
    "    features = [\n",
    "        acc_rate,\n",
    "        conv_rate,\n",
    "        avg_daily_trips\n",
    "    ],\n",
    "    batch_source=FileSource(\n",
    "        event_timestamp_column=\"datetime\",\n",
    "        created_timestamp_column=\"created\",\n",
    "        file_format=ParquetFormat(),\n",
    "        file_url=driver_statistics_source_uri,\n",
    "        date_partition_column=\"date\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_trips_source_uri = os.path.join(demo_data_location, \"driver_trips\")\n",
    "\n",
    "\n",
    "driver_trips = FeatureTable(\n",
    "    name = \"driver_trips\",\n",
    "    entities = [\"driver_id\"],\n",
    "    features = [\n",
    "        trips_today\n",
    "    ],\n",
    "    batch_source=FileSource(\n",
    "        event_timestamp_column=\"datetime\",\n",
    "        created_timestamp_column=\"created\",\n",
    "        file_format=ParquetFormat(),\n",
    "        file_url=driver_trips_source_uri,\n",
    "        date_partition_column=\"date\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering entities and feature tables in Feast Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.apply(driver_id)\n",
    "client.apply(driver_statistics)\n",
    "client.apply(driver_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spec:\n",
      "  name: driver_statistics\n",
      "  entities:\n",
      "  - driver_id\n",
      "  features:\n",
      "  - name: avg_daily_trips\n",
      "    valueType: INT32\n",
      "  - name: acc_rate\n",
      "    valueType: FLOAT\n",
      "  - name: conv_rate\n",
      "    valueType: FLOAT\n",
      "  batchSource:\n",
      "    type: BATCH_FILE\n",
      "    eventTimestampColumn: datetime\n",
      "    datePartitionColumn: date\n",
      "    createdTimestampColumn: created\n",
      "    fileOptions:\n",
      "      fileFormat:\n",
      "        parquetFormat: {}\n",
      "      fileUrl: gs://my-feast-playground-s-11-4744ea70/test_data/feb28_11_10pm/driver_statistics\n",
      "meta:\n",
      "  createdTimestamp: '2021-03-12T06:06:14Z'\n",
      "\n",
      "spec:\n",
      "  name: driver_trips\n",
      "  entities:\n",
      "  - driver_id\n",
      "  features:\n",
      "  - name: trips_today\n",
      "    valueType: INT32\n",
      "  batchSource:\n",
      "    type: BATCH_FILE\n",
      "    eventTimestampColumn: datetime\n",
      "    datePartitionColumn: date\n",
      "    createdTimestampColumn: created\n",
      "    fileOptions:\n",
      "      fileFormat:\n",
      "        parquetFormat: {}\n",
      "      fileUrl: gs://my-feast-playground-s-11-4744ea70/test_data/feb28_11_10pm/driver_trips\n",
      "meta:\n",
      "  createdTimestamp: '2021-03-12T06:06:15Z'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(client.get_feature_table(\"driver_statistics\").to_yaml())\n",
    "print(client.get_feature_table(\"driver_trips\").to_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populating batch source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feast is agnostic to how the batch source is populated, as long as it complies to the Feature Table specification. Therefore, any existing ETL tools can be used for the purpose of data ingestion. Alternatively, you can also use Feast SDK to ingest a Panda Dataframe to the batch source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_entities():\n",
    "    return np.random.choice(999999, size=100, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trips(entities):\n",
    "    df = pd.DataFrame(columns=[\"driver_id\", \"trips_today\", \"datetime\", \"created\"])\n",
    "    df['driver_id'] = entities\n",
    "    df['trips_today'] = np.random.randint(0, 1000, size=100).astype(np.int32)\n",
    "    df['datetime'] = pd.to_datetime(\n",
    "            np.random.randint(\n",
    "                datetime(2020, 10, 10).timestamp(),\n",
    "                datetime(2020, 10, 20).timestamp(),\n",
    "                size=100),\n",
    "        unit=\"s\"\n",
    "    )\n",
    "    df['created'] = pd.to_datetime(datetime.now())\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stats(entities):\n",
    "    df = pd.DataFrame(columns=[\"driver_id\", \"conv_rate\", \"acc_rate\", \"avg_daily_trips\", \"datetime\", \"created\"])\n",
    "    df['driver_id'] = entities\n",
    "    df['conv_rate'] = np.random.random(size=100).astype(np.float32)\n",
    "    df['acc_rate'] = np.random.random(size=100).astype(np.float32)\n",
    "    df['avg_daily_trips'] = np.random.randint(0, 1000, size=100).astype(np.int32)\n",
    "    df['datetime'] = pd.to_datetime(\n",
    "            np.random.randint(\n",
    "                datetime(2020, 10, 10).timestamp(),\n",
    "                datetime(2020, 10, 20).timestamp(),\n",
    "                size=100),\n",
    "        unit=\"s\"\n",
    "    )\n",
    "    df['created'] = pd.to_datetime(datetime.now())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = generate_entities()\n",
    "stats_df = generate_stats(entities)\n",
    "trips_df = generate_trips(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing temporary file(s)...\n",
      "Data has been successfully ingested into FeatureTable batch source.\n",
      "Removing temporary file(s)...\n",
      "Data has been successfully ingested into FeatureTable batch source.\n"
     ]
    }
   ],
   "source": [
    "client.ingest(driver_statistics, stats_df)\n",
    "client.ingest(driver_trips, trips_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical Retrieval For Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a training dataset from offline feature tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "from pyarrow.parquet import ParquetDataset\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_id</th>\n",
       "      <th>event_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>291265</td>\n",
       "      <td>2020-10-19 13:50:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>389275</td>\n",
       "      <td>2020-10-19 21:55:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81792</td>\n",
       "      <td>2020-10-18 08:37:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150997</td>\n",
       "      <td>2020-10-18 03:21:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>227660</td>\n",
       "      <td>2020-10-19 12:48:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>862125</td>\n",
       "      <td>2020-10-18 11:54:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>247351</td>\n",
       "      <td>2020-10-18 14:20:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20501</td>\n",
       "      <td>2020-10-18 19:38:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>888946</td>\n",
       "      <td>2020-10-19 23:06:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>150771</td>\n",
       "      <td>2020-10-19 19:00:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   driver_id     event_timestamp\n",
       "0     291265 2020-10-19 13:50:53\n",
       "1     389275 2020-10-19 21:55:08\n",
       "2      81792 2020-10-18 08:37:32\n",
       "3     150997 2020-10-18 03:21:28\n",
       "4     227660 2020-10-19 12:48:11\n",
       "5     862125 2020-10-18 11:54:01\n",
       "6     247351 2020-10-18 14:20:03\n",
       "7      20501 2020-10-18 19:38:20\n",
       "8     888946 2020-10-19 23:06:46\n",
       "9     150771 2020-10-19 19:00:26"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_with_timestamp = pd.DataFrame(columns=['driver_id', 'event_timestamp'])\n",
    "entities_with_timestamp['driver_id'] = np.random.choice(entities, 10, replace=False)\n",
    "entities_with_timestamp['event_timestamp'] = pd.to_datetime(np.random.randint(\n",
    "    datetime(2020, 10, 18).timestamp(),\n",
    "    datetime(2020, 10, 20).timestamp(),\n",
    "    size=10), unit='s')\n",
    "entities_with_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# get_historical_features will return immediately once the Spark job has been submitted succesfully.\n",
    "job = client.get_historical_features(\n",
    "    feature_refs=[\n",
    "        \"driver_statistics:avg_daily_trips\",\n",
    "        \"driver_statistics:conv_rate\",\n",
    "        \"driver_statistics:acc_rate\",\n",
    "        \"driver_trips:trips_today\"\n",
    "    ], \n",
    "    entity_source=entities_with_timestamp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://my-feast-playground-s-11-4744ea70/historical/d72a3c41-63b0-4c3a-81ce-708a82cf6d74\n"
     ]
    }
   ],
   "source": [
    "# get_output_file_uri will block until the Spark job is completed.\n",
    "output_file_uri = job.get_output_file_uri()\n",
    "print(output_file_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the remote training dataset\n",
    "time.sleep(10)\n",
    "parsed_uri = urlparse(output_file_uri)\n",
    "fs = gcsfs.GCSFileSystem()\n",
    "files = [\"gs://\" + path for path in fs.glob(output_file_uri + '/part-*')]\n",
    "ds = ParquetDataset(files, filesystem=fs)\n",
    "ds.read().to_pandas()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The retrieved result can now be used for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating Online Storage with Batch Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to populate the online storage, we can use Feast SDK to start a Spark batch job which will extract the features from the batch source, then load the features to an online store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = client.start_offline_to_online_ingestion(\n",
    "    driver_statistics,\n",
    "    datetime(2020, 10, 10),\n",
    "    datetime(2020, 10, 20)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SparkJobStatus.IN_PROGRESS: 1>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It will take some time before the Spark Job is completed\n",
    "time.sleep(15)\n",
    "job.get_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the job is completed, the SDK can be used to retrieve the result from the online store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "entities_sample = np.random.choice(entities, 10, replace=False)\n",
    "entities_sample = [{\"driver_id\": e} for e in entities_sample]\n",
    "entities_sample\n",
    "time.sleep(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(15)\n",
    "\n",
    "features = client.get_online_features(\n",
    "    feature_refs=[\"driver_statistics:avg_daily_trips\"],\n",
    "    entity_rows=entities_sample).to_dict()\n",
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_id</th>\n",
       "      <th>driver_statistics:avg_daily_trips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>640707</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>453379</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>227660</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>438103</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>393016</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>861959</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>888946</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>542137</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>209409</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>829291</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   driver_id driver_statistics:avg_daily_trips\n",
       "0     640707                              None\n",
       "1     453379                              None\n",
       "2     227660                              None\n",
       "3     438103                              None\n",
       "4     393016                              None\n",
       "5     861959                              None\n",
       "6     888946                              None\n",
       "7     542137                              None\n",
       "8     209409                              None\n",
       "9     829291                              None"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
